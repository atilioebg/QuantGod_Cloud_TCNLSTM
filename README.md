# QuantGod Cloud âš¡

> **RepositÃ³rio:** [`atilioebg/QuantGod_Cloud_TCNLSTM`](https://github.com/atilioebg/QuantGod_Cloud_TCNLSTM) | **Branch:** `main` | **Status:** ðŸŸ¢ Production Ready
>
> Sistema de prediÃ§Ã£o de direÃ§Ã£o de mercado para **BTC/USDT Perpetual Futures (Bybit/Binance)** usando um ensemble **TCN+LSTM (Base Model) + XGBoost (Auditor)**, treinado em dados Level 2 de Order Book histÃ³ricos de 2023â€“2026.

---

## ðŸ§  O que Ã© o QuantGod?

QuantGod Ã© um sistema de ML de ponta a ponta para sinais de trading em alta frequÃªncia. Dado um histÃ³rico de 12 horas de microestrutura de mercado (720 snapshots de orderbook de 1 minuto), o sistema emite um dos trÃªs sinais:

| Sinal | CÃ³digo | InterpretaÃ§Ã£o |
|:---:|:---:|:---|
| **SELL** | `0` | Retorno < -0.4% nos prÃ³ximos 60 min |
| **NEUTRAL** | `1` | AusÃªncia de direÃ§Ã£o clara â€” nÃ£o negociar |
| **BUY** | `2` | Retorno > +0.8% nos prÃ³ximos 60 min |

---

## ðŸ—ï¸ Arquitetura do Sistema

```
Bybit L2 ZIPs (GDrive, 2023â€“2026)
        â†“
    ETL Pipeline          â† transform.py: book reconstruction, 9 features, 1min resample
        â†“
  pre_processed/*.parquet (810 colunas, ~1.440 linhas/dia)
        â†“
    Labelling             â† run_labelling.py: threshold assimÃ©trico lookahead=60min
        â†“
  labelled_*/*.parquet (810 colunas + target âˆˆ {0,1,2})
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BASE MODEL â€” Hybrid_TCN_LSTM        â”‚
â”‚  Input: (B, 720, 9) â€” 12h Ã— 9 features    â”‚
â”‚  TCN Stack (dilations [1,2,4,8]) + LSTM    â”‚
â”‚  Output: {logits: (B,3), probs: (B,3)}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“ probs + last_step_features
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AUDITOR MODEL â€” XGBoost              â”‚
â”‚  14 meta-features (probs, entropy,         â”‚
â”‚  candle features, RSI, EMA distances)      â”‚
â”‚  Output: calibrated signal + confidence    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Live Inference (Binance Futures WS)
```

---

## ðŸ“‚ Estrutura do RepositÃ³rio

```
QuantGod_Cloud/
â”œâ”€â”€ src/cloud/
â”‚   â”œâ”€â”€ base_model/          â† ETL, Labelling, TCN+LSTM, Optuna, Training
â”‚   â””â”€â”€ auditor_model/       â† XGBoost, Feature Engineering Meta, Binance Live Adapter
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ L2/pre_processed/    â† Output do ETL (810 cols Parquet)
â”‚   â”œâ”€â”€ L2/labelled_*/       â† Datasets rotulados (+ coluna target)
â”‚   â”œâ”€â”€ models/              â† Checkpoints: .pt, .pkl, .json
â”‚   â””â”€â”€ live/                â† Buffer de candles ao vivo
â”œâ”€â”€ tests/                   â† Suite de testes (unitÃ¡rios + integridade + qualidade de dados)
â”œâ”€â”€ docs/                    â† DocumentaÃ§Ã£o tÃ©cnica completa
â””â”€â”€ logs/                    â† Logs de ETL, labelling, optuna, training
```

---

## ðŸ“š DocumentaÃ§Ã£o

| Documento | ConteÃºdo |
|:---|:---|
| ðŸ—ºï¸ **[0_REPO_MAP.md](docs/0_REPO_MAP.md)** | Mapa completo do repositÃ³rio â€” arquivos, configs, artefatos |
| ðŸ› ï¸ **[1_SETUP_AND_ENV.md](docs/1_SETUP_AND_ENV.md)** | Hardware, instalaÃ§Ã£o de dependÃªncias, rclone, checklist |
| ðŸ“¡ **[2_DATA_COLLECTION.md](docs/2_DATA_COLLECTION.md)** | Dados brutos Bybit L2, GDrive, acesso live via Binance |
| âš™ï¸ **[3_DATA_ENGINEERING.md](docs/3_DATA_ENGINEERING.md)** | ETL: schema 810 cols, 9 features com fÃ³rmulas, normalizaÃ§Ã£o |
| ðŸ·ï¸ **[4_LABELING_STRATEGY.md](docs/4_LABELING_STRATEGY.md)** | Thresholds assimÃ©tricos, 8 experimentos, como gerar novos |
| ðŸ¤– **[5_MODEL_ARCHITECTURE.md](docs/5_MODEL_ARCHITECTURE.md)** | **ReferÃªncia arquitetural** â€” TCN+LSTM, XGBoost, constraints, OOF, live adapter |
| ðŸš **[6_OPERATIONAL_MANUAL.md](docs/6_OPERATIONAL_MANUAL.md)** | Pipeline 6 passos, guia RunPod, troubleshooting |
| ðŸ“Š **[7_DATA_REFERENCE.md](docs/7_DATA_REFERENCE.md)** | ReferÃªncia tÃ©cnica detalhada: schema raw, 9 features, labelling, normalizaÃ§Ã£o |

Para a documentaÃ§Ã£o do pipeline de infraestrutura cloud completa, consulte tambÃ©m:
- ðŸ“‹ **[src/cloud/README.md](src/cloud/README.md)** â€” Guia operacional completo

> **Ordem de leitura sugerida:** `0_REPO_MAP` â†’ `1_SETUP` â†’ `2_DATA_COLLECTION` â†’ `3_DATA_ENGINEERING` â†’ `4_LABELING` â†’ `5_MODEL_ARCHITECTURE` â†’ `6_OPERATIONAL_MANUAL` â†’ `7_DATA_REFERENCE` (apÃªndice)

---

## ðŸš€ Quick Start

### Ambiente Local (Windows â€” desenvolvimento/testes)

```powershell
git clone https://github.com/atilioebg/QuantGod_Cloud_TCNLSTM.git
cd QuantGod_Cloud_TCNLSTM
python -m venv venv && venv\Scripts\Activate.ps1
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt

# Testes rÃ¡pidos (sem GPU, sem dados) â€” < 30 segundos
python -m pytest tests/test_config_integrity.py tests/test_meta_features.py tests/test_model.py -v
```

### Treino Completo (RunPod â€” GPU)

```bash
# Ver guia completo em docs/7_OPERATIONAL_MANUAL.md
# Ou em src/cloud/README.md â†’ "Guia RunPod"
```

---

## ðŸ§ª Suite de Testes

```bash
# UnitÃ¡rios (sem dados, sem GPU)
pytest tests/test_model.py tests/test_meta_features.py tests/test_config_integrity.py -v

# Qualidade de dados (requer data/L2/ populado)
pytest tests/test_cloud_etl_output.py tests/test_preprocessed_quality.py -v
pytest tests/test_labelling_output.py -v

# Trocar experimento de labelling
pytest tests/test_labelling_output.py --labelled-dir data/L2/labelled_SELL_0004_BUY_0006_1h -v
```

Consulte **[tests/README.md](tests/README.md)** para documentaÃ§Ã£o completa da suite.

---

## ðŸ”‘ DecisÃµes de Design

| DecisÃ£o | Motivo |
|:---|:---|
| **TCN+LSTM** ao invÃ©s de Transformer puro | O ViViT colapsou em F1â‰ˆ0.29 â€” apenas classe NEUTRAL. TCN garante causalidade local, LSTM mantÃ©m memÃ³ria de longo prazo. |
| **XGBoost como Auditor** | Calibra e filtra prediÃ§Ãµes do base model usando meta-features; treinado em OOF para zero leakage |
| **Thresholds assimÃ©tricos** (BUY=+0.8%, SELL=-0.4%) | Reflete assimetria real de risco/retorno em futuros de BTC |
| **seq_len=720** (12 horas) | Captura contexto de sessÃ£o de mercado sem aumentar VRAM exponencialmente |
| **StandardScaler fit apenas no train** | Garante zero leakage de distribuiÃ§Ã£o entre treino e validaÃ§Ã£o |
| **rclone mount** (nÃ£o download) | Evita ocupar NVMe local com dados brutos; dados de 2023â€“2026 excedem capacidade local |
| **F1 Macro** como mÃ©trica principal | Evita que a classe dominante (NEUTRAL ~65%) mascare erros em SELL/BUY |

---

## ðŸ“‹ DependÃªncias Principais

| Biblioteca | VersÃ£o | Uso |
|:---|:---|:---|
| `torch` | â‰¥ 2.1 | `Hybrid_TCN_LSTM` |
| `xgboost` | â‰¥ 2.0 | Auditor model |
| `polars` | â‰¥ 0.19 | ETL + Labelling |
| `scikit-learn` | â‰¥ 1.3 | StandardScaler, TimeSeriesSplit |
| `optuna` | â‰¥ 3.4 | Hyperparameter search |
| `numpy` | â‰¥ 1.24 | Feature engineering |
| `pyyaml` | â‰¥ 6.0 | Carregamento de configs |

Veja `requirements.txt` para a lista completa.

---

## ðŸŒ¿ Branches

| Branch | Status | DescriÃ§Ã£o |
|:---|:---|:---|
| `main` | ðŸŸ¢ **Ativo** | Arquitetura atual â€” TCN+LSTM ensemble |
