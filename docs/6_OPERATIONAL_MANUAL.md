# üöÅ 7. Operational Manual ‚Äî Pipeline de Execu√ß√£o

> **Target Audience**: MLOps, Operadores de Trading.
> Este manual documenta como executar o pipeline completo do QuantGod Cloud em produ√ß√£o (RunPod) e localmente para desenvolvimento.

---

## üìã Pr√©-Requisitos

Antes de qualquer execu√ß√£o:
1. ‚úÖ Ambiente Python configurado ([`1_SETUP_AND_ENV.md`](1_SETUP_AND_ENV.md))
2. ‚úÖ rclone montado e acessando os ZIPs do GDrive
3. ‚úÖ PYTHONPATH apontando para a raiz do projeto
4. ‚úÖ Configs YAML v√°lidas: `pytest tests/test_config_integrity.py -v`

---

## üó∫Ô∏è Mapa do Pipeline

```mermaid
flowchart LR
    A[ZIPs GDrive] --> B[ETL\nrun_pipeline.py]
    B --> C[pre_processed/\n810 cols Parquet]
    C --> D[Labelling\nrun_labelling.py]
    D --> E[labelled_*/\n+target col]
    E --> F[Optuna\nrun_optuna.py]
    F --> G[training_config.yaml\nbest hyperparams]
    E --> H[Training\nrun_training.py]
    G --> H
    H --> I[models/\n.pt checkpoint\n+ scaler.pkl]
    I --> J[XGBoost\ntrain_xgboost.py]
    E --> J
    I --> J
    J --> K[models/\n.json XGB\n+ OOF metrics]
    K --> L[Live Inference\nbinance_adapter.py]
    I --> L
```

---

## üöÄ Execu√ß√£o Passo a Passo

### Passo 1 ‚Äî ETL

```bash
python -m src.cloud.base_model.pre_processamento.orchestration.run_pipeline
```

- **Input:** ZIPs do GDrive (via rclone mount)
- **Output:** `data/L2/pre_processed/YYYY-MM-DD_*.parquet` (810 colunas, ~1440 linhas/arquivo)
- **Dura√ß√£o:** ~2‚Äì4 horas para o dataset completo (2023‚Äì2026) em 8 vCPUs

**Validar:**
```bash
pytest tests/test_cloud_etl_output.py tests/test_preprocessed_quality.py -v
```

---

### Passo 2 ‚Äî Labelling

```bash
python -m src.cloud.base_model.labelling.run_labelling
```

- **Input:** `data/L2/pre_processed/`
- **Output:** `data/L2/labelled_*/` definido em `labelling_config.yaml` (`output_dir`)
- **Config:** `src/cloud/base_model/labelling/labelling_config.yaml`
- **Dura√ß√£o:** ~30 minutos (paralelo com 6 workers)

**Validar:**
```bash
pytest tests/test_labelling_output.py -v
```

---

### Passo 3 ‚Äî Hyperparameter Optimization (Optuna)

```bash
python -m src.cloud.base_model.otimizacao.run_optuna
```

- **Input:** Dataset labelled (`labelled_dir` em `optimization_config.yaml`)
- **Output:** `data/models/optuna_study.db` (SQLite) ‚Äî melhores HPs logados
- **Config:** `src/cloud/base_model/otimizacao/optimization_config.yaml`
- **Dura√ß√£o:** ~6‚Äì12 horas (50 trials, RTX 4090)
- **Metric:** F1 Macro (evita domin√¢ncia da classe NEUTRAL)

> Se um trial causar OOM, √© automaticamente prunado com `torch.cuda.empty_cache()`.

---

### Passo 4 ‚Äî Treino do Base Model

```bash
python -m src.cloud.base_model.treino.run_training
```

- **Input:** Dataset labelled, best HPs do Optuna (em `training_config.yaml`)
- **Output:** `data/models/base_model.pt` + `data/models/scaler_finetuning.pkl`
- **Config:** `src/cloud/base_model/treino/training_config.yaml`
- **Dura√ß√£o:** ~3‚Äì6 horas (10‚Äì20 √©pocas, EarlyStopping patience=3)

**M√©tricas monitoradas:**
- Train Loss, Val Loss
- F1 Macro (crit√©rio de early stopping)

---

### Passo 5 ‚Äî Treino do Auditor XGBoost

```bash
python -m src.cloud.auditor_model.train_xgboost
```

- **Input:** Dataset labelled + checkpoint do base model
- **Output:** `data/models/xgb_auditor.json` + m√©tricas OOF/test
- **Config:** `src/cloud/auditor_model/configs/auditor_config.yaml`
- **Dura√ß√£o:** ~30‚Äì60 minutos (5 folds OOF)

**Protocolo:** Gera predi√ß√µes Out-of-Fold do base model (sem leakage) e treina XGBoost sobre 14 meta-features.

---

### Passo 6 ‚Äî Live Inference (Binance Futures)

```bash
# Produ√ß√£o
python src/cloud/auditor_model/binance_adapter.py

# Modo de teste (2 candles completos)
python src/cloud/auditor_model/binance_adapter.py --test-mode --max-candles 2
```

- **Requer:** `base_model.pt`, `scaler_finetuning.pkl`, `xgb_auditor.json`
- **Conex√£o:** Binance Futures WebSocket + REST (sem API key para leitura p√∫blica)
- **Frequ√™ncia:** 1 predi√ß√£o/minuto

**Sa√≠da por candle:**
```
[2026-02-20 15:30:00] Signal: BUY | Confidence: 0.821 | Base: BUY(0.743) | Entropy: 0.312
  Features ‚Äî Z-score drift check: all OK
```

---

## üñ•Ô∏è Guia Completo RunPod (Pod Fresh)

```bash
# 1. Clonar e configurar
git clone https://github.com/atilioebg/QuantGod_Cloud_TCNLSTM.git /workspace
cd /workspace
python -m venv venv && source venv/bin/activate
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
export PYTHONPATH=/workspace

# 2. rclone
mkdir -p /root/.config/rclone/
cp rclone.conf /root/.config/rclone/rclone.conf
mkdir -p /workspace/gdrive
rclone mount drive: /workspace/gdrive --vfs-cache-mode full --allow-other &

# 3. Ajustar cloud_config.yaml
#    rclone_mount: "/workspace/gdrive/PROJETOS/BTC_USDT_L2_2023_2026"

# 4. Testes b√°sicos (sem dados)
pytest tests/test_config_integrity.py tests/test_meta_features.py tests/test_model.py -v

# 5. Pipeline completo
#    (em sess√µes tmux separadas para n√£o perder progresso)
tmux new -s etl       # python -m src.cloud.base_model.pre_processamento.orchestration.run_pipeline
tmux new -s label     # python -m src.cloud.base_model.labelling.run_labelling
tmux new -s optuna    # python -m src.cloud.base_model.otimizacao.run_optuna
tmux new -s train     # python -m src.cloud.base_model.treino.run_training
tmux new -s xgb       # python -m src.cloud.auditor_model.train_xgboost
tmux new -s live      # python src/cloud/auditor_model/binance_adapter.py
```

---

## üîß Troubleshooting

| Problema | Causa | Solu√ß√£o |
|:---|:---|:---|
| `ModuleNotFoundError: src` | PYTHONPATH n√£o configurado | `export PYTHONPATH=/workspace` |
| `CUDA out of memory` | batch_size ou seq_len muito alto | Optuna aplica OOM guard automaticamente; reduza `batch_size` em `training_config.yaml` |
| `No ZIP files found` | rclone n√£o montado ou path errado | `rclone lsd drive:` e verifique `cloud_config.yaml` ‚Üí `rclone_mount` |
| `Dataset vazio no labelling` | `labelling_config.yaml` ‚Üí `input_dir` incorreto | Verificar que `pre_processed/` tem arquivos `.parquet` |
| `XGBoost: base model checkpoint not found` | `auditor_config.yaml` ‚Üí `base_model_checkpoint` incorreto | Verificar que `run_training.py` salvou o `.pt` corretamente |
| `test_config_integrity FAIL: labelled_dir mismatch` | `training_config.yaml` e `auditor_config.yaml` com dirs diferentes | Sincronizar `labelled_dir` nos dois arquivos |

---

## üìä Monitoramento de Logs

Logs s√£o salvos automaticamente em `logs/`:

| Log | Localiza√ß√£o | Atualiza√ß√£o |
|:---|:---|:---|
| ETL progress | `logs/etl/etl_YYYYMMDD.log` | A cada arquivo processado |
| Labelling | `logs/labelling/labelling_YYYYMMDD.log` | A cada arquivo labelled |
| Optuna trial | `logs/optimization/optuna_<study>_<timestamp>.log` | A cada trial |
| Training epoch | `logs/training/train_YYYYMMDD.log` | A cada √©poca |
| Debug plots | `logs/debug_plots/` | Por demanda manual |

Consulte `logs/LOGS_README.md` para detalhes completos de conven√ß√µes e reten√ß√£o.
