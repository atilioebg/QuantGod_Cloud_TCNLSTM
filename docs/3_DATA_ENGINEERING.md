# âš™ï¸ 3. Data Engineering (ETL)

> **Target Audience**: Data Engineers, Quants.
> **Script:** `src/cloud/base_model/pre_processamento/orchestration/run_pipeline.py`
> **Config:** `src/cloud/base_model/pre_processamento/configs/cloud_config.yaml`

---

## ğŸš€ ExecuÃ§Ã£o

```bash
# Montar dados (rclone) antes de rodar
python -m src.cloud.base_model.pre_processamento.orchestration.run_pipeline

# Validar output
pytest tests/test_cloud_etl_output.py tests/test_preprocessed_quality.py -v
```

---

## ğŸ”„ Fluxo do ETL

```
ZIP (GDrive/Bybit L2)
  â”‚
  â”œâ”€ extract.py: Leitura recursiva de ZIPs (suporta ob200 e ob500)
  â”‚
  â”œâ”€ transform.py: ReconstruÃ§Ã£o do orderbook tick a tick
  â”‚   â”œâ”€ AplicaÃ§Ã£o de snapshots e deltas (size=0 â†’ remoÃ§Ã£o de nÃ­vel)
  â”‚   â”œâ”€ Hard Cut: top 200 bids (desc) + top 200 asks (asc)
  â”‚   â”œâ”€ Sampling: 1 tick/segundo (1000ms)
  â”‚   â”œâ”€ CÃ¡lculo por tick: micro_price, spread, obi_l0, deep_obi_5, tick_count
  â”‚   â””â”€ Resample 1 minuto: OHLC + 9 features agregadas
  â”‚
  â”œâ”€ load.py: SerializaÃ§Ã£o em Parquet com compressÃ£o snappy
  â”‚
  â””â”€ validate.py: NaN check, Infinity, ordem temporal, gaps
```

---

## ğŸ“ Hard Cut â€” ob500 â†’ ob200

Arquivos de 2023 possuem 500 nÃ­veis de profundidade. O pipeline aplica corte automÃ¡tico:

```python
sorted_bids = sorted(self.bids_book.keys(), reverse=True)[:200]  # Top 200 bids
sorted_asks = sorted(self.asks_book.keys())[:200]                 # Top 200 asks
```

Isso garante **schema de colunas idÃªntico** para todos os anos (810 colunas), sem qualquer branch especial no cÃ³digo de treinamento.

---

## ğŸ“Š Output: Schema do Parquet

Cada arquivo `data/L2/pre_processed/YYYY-MM-DD_BTCUSDT_ob*.parquet` possui **810 colunas** e ~1.440 linhas (1 minuto por linha):

| Grupo | PadrÃ£o | Qtd | DescriÃ§Ã£o |
|:---|:---|:---:|:---|
| Bids â€” PreÃ§o | `bid_{0..199}_p` | 200 | PreÃ§o do nÃ­vel i (bid_0 = best bid) |
| Bids â€” Tamanho | `bid_{0..199}_s` | 200 | Quantidade do nÃ­vel i |
| Asks â€” PreÃ§o | `ask_{0..199}_p` | 200 | PreÃ§o do nÃ­vel i (ask_0 = best ask) |
| Asks â€” Tamanho | `ask_{0..199}_s` | 200 | Quantidade do nÃ­vel i |
| Features | *(ver abaixo)* | 9 | Input direto do modelo |
| ReferÃªncia | `close` | 1 | Micro-price de fechamento |
| **TOTAL** | | **810** | |

**OrdenaÃ§Ã£o garantida:** `bid_0_p > bid_1_p > ... > bid_199_p` (decrescente), `ask_0_p < ask_1_p < ... < ask_199_p` (crescente).

**Index:** `datetime` em UTC, frequÃªncia de 1 minuto.

---

## ğŸ§® As 9 Features Derivadas

Estas sÃ£o as **Ãºnicas colunas** passadas como input ao modelo `Hybrid_TCN_LSTM`. Calculadas durante o resample de 1 minuto sobre os ticks de 1 segundo:

### Features de Candle (Forma da Vela)

| Feature | FÃ³rmula | DescriÃ§Ã£o |
|:---|:---|:---|
| `body` | `log(close / open)` | Retorno log do corpo â€” positivo = alta, negativo = queda |
| `upper_wick` | `(high - max(open, close)) / prev_close` | Sombra superior normalizada pelo fechamento anterior |
| `lower_wick` | `(min(open, close) - low) / prev_close` | Sombra inferior normalizada pelo fechamento anterior |

> **OHLC** Ã© derivado da `micro_price` durante o resample. `close` = micro_price no fechamento do minuto.

### Feature de Retorno

| Feature | FÃ³rmula | DescriÃ§Ã£o |
|:---|:---|:---|
| `log_ret_close` | `log(close / prev_close)` | Log-retorno â€” sÃ©rie estacionÃ¡ria para ML |

> Esta coluna tambÃ©m Ã© a base para reconstruir micro_price durante feature engineering do XGBoost (via `cumsum` dos log-retornos).

### Features de Microestrutura (Orderbook)

| Feature | FÃ³rmula | DescriÃ§Ã£o |
|:---|:---|:---|
| `volatility` | `std(micro_price_ticks_1s)` | Desvio padrÃ£o da micro_price intra-candle |
| `max_spread` | `max(ask_0_p - bid_0_p)_ticks_1s` | Spread mÃ¡ximo bid-ask no minuto â€” proxy de stress de liquidez |
| `mean_obi` | `mean((bid_0_s - ask_0_s)/(bid_0_s + ask_0_s))` | OBI top 1 nÃ­vel â€” range [-1, +1] |
| `mean_deep_obi` | `mean((Î£bid_0..4_s - Î£ask_0..4_s)/(Î£bid + Î£ask))` | OBI dos top 5 nÃ­veis â€” liquidez mais representativa |
| `log_volume` | `log1p(tick_count)` | Proxy de volume â€” count de mensagens L2 no minuto |

---

## ğŸ”¬ VariÃ¡veis Auxiliares (nÃ£o sÃ£o input do modelo)

| VariÃ¡vel | DescriÃ§Ã£o | Uso |
|:---|:---|:---|
| `micro_price` | `(bid_0_p Ã— ask_0_s + ask_0_p Ã— bid_0_s) / (bid_0_s + ask_0_s)` | Gera OHLC e log_ret_close |
| `spread` | `ask_0_p - bid_0_p` | Gera `max_spread` |
| `obi_l0` | `(bid_0_s - ask_0_s) / (bid_0_s + ask_0_s)` | Gera `mean_obi` |
| `deep_obi_5` | OBI dos top 5 nÃ­veis | Gera `mean_deep_obi` |
| `tick_count` | Count de mensagens L2/minuto | Gera `log_volume` |
| `close` | Micro-price de fechamento | ReferÃªncia para labelling |
| `bid_{i}_p/s`, `ask_{i}_p/s` | Estado do book no fechamento do minuto | ReferÃªncia para inspeÃ§Ã£o/debug |

---

## ğŸ“ NormalizaÃ§Ã£o dos Inputs

Antes de entrar no modelo, as 9 features recebem Z-Score via `StandardScaler`:

```python
scaler = StandardScaler()
scaler.fit(X_train)      # Fit APENAS no conjunto de treino â€” sem leakage
X_train_norm = scaler.transform(X_train)
X_val_norm   = scaler.transform(X_val)
```

O scaler treinado Ã© salvo em `data/models/scaler_finetuning.pkl` e carregado durante:
- Treino do XGBoost (normalizaÃ§Ã£o dos meta-features)
- InferÃªncia live no `binance_adapter.py`

---

## ğŸ• Timeframe dos Dados

```
Bybit WebSocket L2 ticks (~100ms de frequÃªncia)
    â†’ Sampling 1s    â†’ ~86.400 linhas/dia (1 por segundo)
    â†’ Resample 1min  â†’ ~1.440 linhas/dia  (1 por minuto) â† Output final
```

**Janela de lookback do modelo:** 720 candles Ã— 1 min = **12 horas de histÃ³rico**.

---

## ğŸ” ValidaÃ§Ã£o do Output ETL

```bash
# Verifica 810 colunas, ordenaÃ§Ã£o do OB, sem NaN nas features, timestamps cronolÃ³gicos
pytest tests/test_cloud_etl_output.py -v

# Verifica contagem de linhas (~1440/dia), continuidade de datas, schema
pytest tests/test_preprocessed_quality.py -v
```

Consulte [`data/README.md`](../data/README.md) para detalhes do volume de dados atual.
