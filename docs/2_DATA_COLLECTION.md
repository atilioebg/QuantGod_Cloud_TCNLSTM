# üì° 2. Data Collection (Dados Brutos)

> **Target Audience**: Data Engineers.
> **Status:** Os dados hist√≥ricos est√£o coletados e armazenados no Google Drive. Esta se√ß√£o documenta como foram obtidos e como acess√°-los.

---

## üì¶ Fonte dos Dados

| Atributo | Valor |
|:---|:---|
| **Exchange** | Bybit Futures (hist√≥rico) / Binance Futures (live) |
| **Par** | BTC/USDT Perpetual Futures |
| **Tipo** | Level 2 Order Book ‚Äî Profundidade Completa |
| **Formato** | Arquivos `.zip` contendo mensagens JSON |
| **Per√≠odo** | 2023-01-01 a 2026-02-xx |
| **Localiza√ß√£o** | Google Drive: `drive:PROJETOS/BTC_USDT_L2_2023_2026/` |
| **Tamanho total** | ~35.7 GB processado (`data/L2/pre_processed/`) |

---

## üìÇ Organiza√ß√£o dos Dados Brutos no Google Drive

```
drive:PROJETOS/BTC_USDT_L2_2023_2026/
‚îú‚îÄ‚îÄ 2023/
‚îÇ   ‚îú‚îÄ‚îÄ 2023-01-01_BTCUSDT_ob500.data.zip
‚îÇ   ‚îú‚îÄ‚îÄ 2023-01-02_BTCUSDT_ob500.data.zip
‚îÇ   ‚îî‚îÄ‚îÄ ...  (365 arquivos ob500 ‚Äî 500 n√≠veis de profundidade)
‚îú‚îÄ‚îÄ 2024/
‚îÇ   ‚îú‚îÄ‚îÄ 2024-01-01_BTCUSDT_ob200.data.zip
‚îÇ   ‚îî‚îÄ‚îÄ ...  (366 arquivos ob200 ‚Äî 200 n√≠veis)
‚îú‚îÄ‚îÄ 2025/
‚îÇ   ‚îî‚îÄ‚îÄ ...  (ob200)
‚îî‚îÄ‚îÄ 2026/
    ‚îî‚îÄ‚îÄ ...  (ob200, at√© data atual)
```

### Mudan√ßa de Profundidade em 2024

| Per√≠odo | Profundidade | Arquivo |
|:---|:---|:---|
| 2023 | OB500 | `*_ob500.data.zip` |
| 2024‚Äì2026 | OB200 | `*_ob200.data.zip` |

> O ETL aplica **Hard Cut autom√°tico para 200 n√≠veis** nos arquivos OB500, garantindo schema id√™ntico para todos os anos.

---

## üìã Estrutura de Cada ZIP

Cada ZIP cont√©m um √∫nico arquivo `.data` com sequ√™ncia de mensagens JSON (uma por linha):

### Mensagem `snapshot` (Estado Inicial)
```json
{
  "type": "snapshot",
  "ts": 1704067200000,
  "data": {
    "b": [["43100.5", "1.234"], ["43100.0", "0.890"]],
    "a": [["43101.0", "2.100"], ["43101.5", "0.456"]]
  }
}
```

### Mensagem `delta` (Atualiza√ß√£o Incremental)
```json
{
  "type": "delta",
  "ts": 1704067200150,
  "data": {
    "b": [["43100.5", "0.000"], ["43099.0", "5.000"]],
    "a": [["43102.0", "1.500"]]
  }
}
```

> **‚ö†Ô∏è Tamanho `"0.000"` em delta = remo√ß√£o do n√≠vel de pre√ßo** (n√£o √© um n√≠vel com liquidez zero).

---

## üîå Acessar os Dados

Os dados ficam no Google Drive e s√£o acessados via `rclone mount`:

```bash
# Linux/RunPod ‚Äî montar em background
rclone mount drive: /workspace/gdrive --vfs-cache-mode full --allow-other &

# Verificar acesso
ls /workspace/gdrive/PROJETOS/BTC_USDT_L2_2023_2026/2024/ | head -5
```

Para download direto ao NVMe (acesso mais r√°pido durante treino):
```bash
# Download do dataset labelled ativo para disco local
tmux new -s download
mkdir -p /workspace/data/L2/labelled_SELL_0004_BUY_0008_1h
rclone copy drive:PROJETOS/L2/labelled_SELL_0004_BUY_0008_1h \
  /workspace/data/L2/labelled_SELL_0004_BUY_0008_1h -P
```

Consulte `src/cloud/README.md` ‚Üí Se√ß√£o **Guia Completo RunPod** para o fluxo detalhado.

---

## üîÑ Pipeline de Processamento

Os dados brutos n√£o s√£o usados diretamente pelo modelo. O fluxo completo √©:

```
ZIPs (GDrive/Bybit)  ‚Üí  ETL (transform.py)  ‚Üí  pre_processed/*.parquet
                                                          ‚Üì
                                                labelling (run_labelling.py)
                                                          ‚Üì
                                              labelled_*/*.parquet + coluna target
                                                          ‚Üì
                                                Treino / Optuna / XGBoost
```

Para detalhes de cada etapa, veja:
- **ETL:** [`3_DATA_ENGINEERING.md`](3_DATA_ENGINEERING.md)
- **Labelling:** [`5_LABELING_STRATEGY.md`](5_LABELING_STRATEGY.md)
- **Pipeline completo:** [`src/cloud/README.md`](../src/cloud/README.md)

---

## üî¥ Dados Live (Infer√™ncia em Produ√ß√£o)

Durante infer√™ncia ao vivo, o sistema **n√£o usa os ZIPs do GDrive**. Em vez disso, o `binance_adapter.py` conecta via WebSocket ao Binance Futures e reconstr√≥i o orderbook em tempo real, aplicando a **mesma l√≥gica** de feature engineering do ETL hist√≥rico.

| Aspecto | Treinamento (Bybit) | Live (Binance) |
|:---|:---|:---|
| Fonte | ZIPs hist√≥ricos `.data` | WebSocket `btcusdt@depth@100ms` |
| Snapshot inicial | `"type":"snapshot"` no arquivo | REST GET `/fapi/v1/depth?limit=1000` |
| Sync | Sequencial por arquivo | `lastUpdateId/U/u` + re-bootstrap |
| Features geradas | Id√™nticas (9 features) | Id√™nticas (9 features) |
| Scaler | `StandardScaler.fit()` no train set | `scaler_finetuning.pkl` carregado |

Veja [`docs/TCN_LSTM.md`](TCN_LSTM.md) ‚Üí Se√ß√£o 7 para a documenta√ß√£o completa do `binance_adapter.py`.
