# ‚òÅÔ∏è QuantGod Cloud Infrastructure ‚Äî `src/cloud/`

Pipeline modular de ETL, Labelling, Treinamento e Infer√™ncia do QuantGod, projetado para executar em inst√¢ncias de nuvem (RunPod) ou localmente.

---

## üìÇ Estrutura de Diret√≥rios

```
src/cloud/
‚îú‚îÄ‚îÄ README.md                                 ‚Üê Este arquivo
‚îÇ
‚îú‚îÄ‚îÄ base_model/                               ‚Üê Modelo base: Hybrid TCN+LSTM
‚îÇ   ‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base_model_config.yaml            ‚Üê ‚≠ê Source of truth (class_weights, features, seq_len)
‚îÇ   ‚îú‚îÄ‚îÄ labelling/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_labelling.py                  ‚Üê Gerador de targets SELL/NEUTRAL/BUY
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labelling_config.yaml             ‚Üê Thresholds e lookahead
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.py                          ‚Üê Hybrid_TCN_LSTM (CausalConv1D + LSTM + MLP)
‚îÇ   ‚îú‚îÄ‚îÄ otimizacao/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_optuna.py                     ‚Üê Busca bayesiana de hiperpar√¢metros
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimization_config.yaml          ‚Üê Search space e limites
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best_params.json                  ‚Üê Resultado do Optuna (gerado automaticamente)
‚îÇ   ‚îú‚îÄ‚îÄ pre_processamento/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestration/run_pipeline.py     ‚Üê Orquestrador do ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl/extract.py                    ‚Üê Leitura de ZIPs (GDrive/local)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl/transform.py                  ‚Üê Reconstru√ß√£o do book ‚Üí 9 features
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl/load.py                       ‚Üê Serializa√ß√£o Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl/validate.py                   ‚Üê NaN check, order, gaps
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configs/cloud_config.yaml         ‚Üê Paths e config do ETL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ configs/test_local.yaml           ‚Üê Config para dev local
‚îÇ   ‚îî‚îÄ‚îÄ treino/
‚îÇ       ‚îú‚îÄ‚îÄ run_training.py                   ‚Üê Loop de treino final
‚îÇ       ‚îî‚îÄ‚îÄ training_config.yaml              ‚Üê Hiperpar√¢metros + paths de output
‚îÇ
‚îî‚îÄ‚îÄ auditor_model/                            ‚Üê Modelo auditor: XGBoost
    ‚îú‚îÄ‚îÄ configs/
    ‚îÇ   ‚îî‚îÄ‚îÄ auditor_config.yaml               ‚Üê Walk-forward K, XGBoost params
    ‚îú‚îÄ‚îÄ feature_engineering_meta.py           ‚Üê 14 meta-features sem warm-up
    ‚îú‚îÄ‚îÄ train_xgboost.py                      ‚Üê OOF walk-forward training
    ‚îî‚îÄ‚îÄ binance_adapter.py                    ‚Üê Integra√ß√£o live Binance Futures WS
```

---

## üõ†Ô∏è Configura√ß√£o do Ambiente

### Instala√ß√£o de Depend√™ncias

```bash
pip install -r requirements.txt
```

### Conex√£o com Dados (rclone)

O pipeline n√£o baixa os dados brutos para o disco local. Usa **stream via mount** do Google Drive.

**Windows (dev local):**
```powershell
.\rclone.exe mount drive: Z: --vfs-cache-mode full --config rclone.conf
# ‚ö†Ô∏è Mantenha esta janela aberta enquanto trabalhar
```

**Linux (RunPod):**
```bash
mkdir -p /workspace/gdrive
rclone mount drive: /workspace/gdrive --vfs-cache-mode full --allow-other &
```

> **Aten√ß√£o ao path:** edite `cloud_config.yaml` conforme o ambiente:
> - Local Windows: `rclone_mount: "Z:/PROJETOS/..."`
> - RunPod/Linux: `rclone_mount: "/workspace/gdrive/..."`

---

## üöÄ Pipeline de Execu√ß√£o ‚Äî Ordem Obrigat√≥ria

```
[1. ETL] ‚Üí [2. Labelling] ‚Üí [3. Optuna] ‚Üí [4. Training] ‚Üí [5. XGBoost] ‚Üí [6. Live]
```

---

## 1Ô∏è‚É£ ETL ‚Äî Pr√©-Processamento

**Script:** `base_model/pre_processamento/orchestration/run_pipeline.py`
**Config:** `base_model/pre_processamento/configs/cloud_config.yaml`

```bash
# RunPod (usar tmux para processos longos)
tmux new -s etl
export PYTHONPATH=$PYTHONPATH:/workspace
python -m src.cloud.base_model.pre_processamento.orchestration.run_pipeline
```

**O que faz:**
1. `extract.py` ‚Äî Lista e l√™ ZIPs recursivamente do GDrive (suporta ob200 e ob500)
2. `transform.py` ‚Äî Reconstr√≥i o orderbook tick a tick ‚Üí resample 1 segundo ‚Üí 1 minuto ‚Üí calcula 9 features estacion√°rias
3. `load.py` ‚Äî Salva em `data/L2/pre_processed/YYYY-MM-DD_BTCUSDT_ob*.parquet`
4. `validate.py` ‚Äî Verifica NaNs, Infinity, ordena√ß√£o temporal e gaps

**Features geradas (9 colunas):**

| Feature | Descri√ß√£o |
|:---|:---|
| `body` | Log-retorno Open‚ÜíClose do candle |
| `upper_wick` | Sombra superior / close anterior |
| `lower_wick` | Sombra inferior / close anterior |
| `log_ret_close` | Log-retorno Close‚ÜíClose |
| `volatility` | Std dos micro-pre√ßos no minuto |
| `max_spread` | Spread bid-ask m√°ximo do minuto |
| `mean_obi` | M√©dia do Order Book Imbalance L0 |
| `mean_deep_obi` | M√©dia do Deep OBI (top 5 n√≠veis) |
| `log_volume` | log1p(tick_count) ‚Äî proxy de volume |

**Valida√ß√£o:**
```bash
pytest tests/test_cloud_etl_output.py
pytest tests/test_preprocessed_quality.py
```

**Hardware recomendado:** 8+ vCPUs / 16 GB RAM (CPU-bound, sem GPU).

---

## 2Ô∏è‚É£ Labelling ‚Äî Gera√ß√£o de Targets

**Script:** `base_model/labelling/run_labelling.py`
**Config:** `base_model/labelling/labelling_config.yaml`

```bash
python -m src.cloud.base_model.labelling.run_labelling
```

**L√≥gica de Labelling (Thresholds Assim√©tricos):**

| Label | Valor | Condi√ß√£o |
|:---:|:---|:---|
| `0` | SELL | `future_return < threshold_short` (default: -0.4%) |
| `1` | NEUTRAL | Entre os thresholds |
| `2` | BUY | `future_return > threshold_long` (default: +0.8%) |

O retorno futuro √© calculado sobre uma janela de `lookahead` minutos (default: 60 min).

**Experimentos dispon√≠veis em `data/L2/`:**

| Pasta | Short | Long | Lookahead |
|:---|:---:|:---:|:---:|
| `labelled_SELL_0004_BUY_0008_1h` | -0.4% | +0.8% | 60 min | **‚Üê ativo** |
| `labelled_SELL_0004_BUY_0006_1h` | -0.4% | +0.6% | 60 min | |
| `labelled_SELL_0004_BUY_0005_1h` | -0.4% | +0.5% | 60 min | |
| `labelled_SELL_0004_BUY_0004_1h` | -0.4% | +0.4% | 60 min | |
| `labelled_SELL_0004_BUY_0008_2h` | -0.4% | +0.8% | 120 min | |
| `labelled_SELL_0004_BUY_0004_2h` | -0.4% | +0.4% | 120 min | |
| `labelled_SELL_0004_BUY_001_2h` | -0.4% | +1.0% | 120 min | |
| `labelled_SELL_0003_BUY_0005_1h` | -0.3% | +0.5% | 60 min | |

**Valida√ß√£o:**
```bash
pytest tests/test_labelling_output.py
```

**Output:** `data/L2/labelled_{CONFIG}/YYYY-MM-DD_BTCUSDT_ob*.parquet` ‚Äî mesmo schema do `pre_processed/` + coluna `target`.

---

## 3Ô∏è‚É£ Optuna ‚Äî Otimiza√ß√£o de Hiperpar√¢metros

**Script:** `base_model/otimizacao/run_optuna.py`
**Config:** `base_model/otimizacao/optimization_config.yaml`

```bash
python -m src.cloud.base_model.otimizacao.run_optuna
```

**Configura√ß√£o:**

| Par√¢metro | Valor |
|:---|:---|
| Trials | 30 |
| Timeout | 10 horas |
| M√©trica | F1 Macro (n√£o weighted ‚Äî evita domin√¢ncia do NEUTRAL) |
| Pruner | `MedianPruner(n_startup_trials=5, n_warmup_steps=2)` |

**Search Space:**

| Hiperpar√¢metro | Valores Candidatos |
|:---|:---|
| `tcn_channels` | 32, 64, 128 |
| `lstm_hidden` | 128, 256, 512 |
| `num_lstm_layers` | 1, 2 |
| `lr` | [5e-5, 1e-3] (log-uniform) |
| `dropout` | [0.2, 0.5] |
| `batch_size` | 128, 256 (512 exclu√≠do ‚Äî OOM com lstm=512 + seq=1440) |
| `seq_len` | 720 (12h), 1440 (24h) |
| `epochs` por trial | 5 |

**OOM Guard:** Se qualquer trial levantar `RuntimeError("out of memory")`, o c√≥digo executa `torch.cuda.empty_cache()` e registra `optuna.TrialPruned()` ‚Äî nunca trava a busca.

**Outputs:**
- `best_params.json` ‚Äî par√¢metros do melhor trial
- `optuna_tcn_lstm_v1.db` ‚Äî hist√≥rico completo (SQLite)

```bash
# Visualizar dashboard Optuna
optuna-dashboard sqlite:///optuna_tcn_lstm_v1.db
# ‚Üí http://127.0.0.1:8080
```

---

## 4Ô∏è‚É£ Treino Final ‚Äî Base Model (`Hybrid_TCN_LSTM`)

**Script:** `base_model/treino/run_training.py`
**Config:** `base_model/treino/training_config.yaml`
**Config compartilhada:** `base_model/configs/base_model_config.yaml` ‚Üê fonte √∫nica de verdade

```bash
python -m src.cloud.base_model.treino.run_training
```

### Arquitetura: `Hybrid_TCN_LSTM`

```
Input (B, 720, 9)
  ‚Üí TCN Stack: 4 √ó CausalConv1D
      dilation=[1, 2, 4, 8], kernel=3
      + Residual connection + BatchNorm + GELU + SpatialDropout
  ‚Üí LSTM (hidden=256, layers=2, batch_first=True, dropout=0.2)
      ‚Üí last hidden state h_n[-1]: (B, 256)
  ‚Üí MLP Head: Linear(256‚Üí128) ‚Üí GELU ‚Üí Dropout(0.4) ‚Üí Linear(128‚Üí3)
Output: { "logits": (B, 3), "probs": softmax(B, 3) }
```

**Causal Convolution:** padding = `dilation √ó (kernel_size ‚àí 1)` √† esquerda + trim √† direita. `output[t]` depende apenas de `input[t-k], k‚â•0`. Zero leakage de futuro.

### Regime de Treinamento

| Par√¢metro | Valor | Justificativa |
|:---|:---|:---|
| `seq_len` | 720 passos (12h) | Lookback que captura ciclos intraday completos |
| `batch_size` | 256 | Balan√ßo I/O / VRAM |
| `lr` inicial | 0.0003 | Ponto de partida AdamW est√°vel para LSTM |
| `optimizer` | `AdamW(weight_decay=0.01)` | L2 correto para sequ√™ncias (vs Adam puro) |
| `scheduler` | `CosineAnnealingLR` | Decaimento suave, evita steps abruptos |
| `gradient_clip_norm` | 1.0 | Previne exploding gradients no LSTM BPTT |
| `loss` | `CrossEntropyLoss(weight=[2.0, 1.0, 2.0])` | SELL e BUY 2√ó mais penalizados que NEUTRAL |
| `early_stopping` | patience=3, crit√©rio=F1 Macro | Para no melhor F1 real, n√£o no menor loss |
| `epochs` m√°x | 10 | |

### Divis√£o do Dataset

```
Dataset cronol√≥gico completo (1.126 dias, 2023-01 a 2026-02):

‚îú‚îÄ‚îÄ Treino (80% primeiros dias)
‚îÇ   ‚îî‚îÄ‚îÄ StandardScaler fit APENAS aqui
‚îî‚îÄ‚îÄ Valida√ß√£o (20% √∫ltimos dias ‚Äî nunca visto no treino)
    ‚îî‚îÄ‚îÄ Crit√©rio de early stopping (F1 Macro)
```

> ‚ö†Ô∏è **Zero look-ahead:** o split √© estritamente temporal. O scaler nunca v√™ dados de valida√ß√£o. O `StandardScaler` fitted √© salvo em `data/models/scaler_finetuning.pkl` ‚Äî usado id√™ntico em treino, valida√ß√£o e infer√™ncia ao vivo.

### Outputs

| Arquivo | Conte√∫do |
|:---|:---|
| `data/models/best_tcn_lstm.pt` | Checkpoint com melhor F1 Macro na valida√ß√£o |
| `data/models/scaler_finetuning.pkl` | StandardScaler fitted no train set |

---

## 5Ô∏è‚É£ XGBoost Auditor ‚Äî Walk-Forward OOF

**Script:** `auditor_model/train_xgboost.py`
**Eng. Features:** `auditor_model/feature_engineering_meta.py`
**Config:** `auditor_model/configs/auditor_config.yaml`

```bash
python -m src.cloud.auditor_model.train_xgboost
```

### Regime de Treinamento: Out-of-Fold Walk-Forward

O XGBoost √© um **segundo est√°gio** que aprende a calibrar, corrigir e vetar as predi√ß√µes do TCN+LSTM. Para evitar qualquer leakage ‚Äî o XGBoost **nunca** v√™ predi√ß√µes geradas em dados que o TCN+LSTM usou para treinar.

**Protocolo de divis√£o:**

```
Dataset completo (cronol√≥gico)
‚îú‚îÄ‚îÄ 90% ‚Äî DEV set
‚îÇ   Dividido em K=5 folds via TimeSeriesSplit (temporal, sem shuffle)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Fold 1: [TRAIN ‚Üí TCN+LSTM] | Fold 2: [OOF predictions geradas]
‚îÇ   ‚îú‚îÄ‚îÄ Fold 2: [TRAIN ‚Üí TCN+LSTM] | Fold 3: [OOF predictions geradas]
‚îÇ   ‚îú‚îÄ‚îÄ Fold 3: [TRAIN ‚Üí TCN+LSTM] | Fold 4: [OOF predictions geradas]
‚îÇ   ‚îî‚îÄ‚îÄ Fold 4: [TRAIN ‚Üí TCN+LSTM] | Fold 5: [OOF predictions geradas]
‚îÇ
‚îÇ   Pool OOF acumulado = OOF‚ÇÇ + OOF‚ÇÉ + OOF‚ÇÑ + OOF‚ÇÖ
‚îÇ   XGBoost TREINA neste pool
‚îÇ
‚îî‚îÄ‚îÄ 10% ‚Äî TEST set (nunca tocado durante nenhuma etapa)
    ‚îî‚îÄ‚îÄ Avalia√ß√£o final do ensemble (TCN+LSTM + XGBoost)
```

> **Regra inviol√°vel:** O XGBoost treina EXCLUSIVAMENTE em predi√ß√µes OOF ‚Äî nunca em predi√ß√µes in-sample.

### 14 Meta-Features (Input do XGBoost)

| # | Feature | Fonte |
|:---|:---|:---|
| 0‚Äì2 | `prob_sell, prob_neutral, prob_buy` | Output `softmax` do TCN+LSTM |
| 3 | `entropy` = -Œ£ p¬∑log(p) | Incerteza do modelo |
| 4‚Äì10 | `body, upper_wick, lower_wick, log_ret_close, volatility, mean_obi, mean_deep_obi` | √öltimo timestep do tensor (t=720) |
| 11 | `rsi_14` | Calculado do tensor micro_price (sem warm-up) |
| 12 | `ema_9_dist` | % dist√¢ncia para EMA de 9 per√≠odos |
| 13 | `ema_50_dist` | % dist√¢ncia para EMA de 50 per√≠odos |

**Zero warm-up:** RSI e EMAs s√£o extra√≠dos da janela de 720 passos j√° em mem√≥ria:
```python
log_rets = X_sequences[:, :, 3]                     # col log_ret_close
micro_prices = np.exp(np.cumsum(log_rets, axis=1))  # (B, 720)
rsi_14 = _rsi(micro_prices[j], period=14)           # 720 pontos dispon√≠veis
```

**Exclu√≠dos:** `max_spread` (‚â•0.8 correla√ß√£o com `volatility`), `log_volume` (baixo sinal p√≥s-probs).

### Hiperpar√¢metros XGBoost

| Par√¢metro | Valor |
|:---|:---|
| `n_estimators` | 500 |
| `max_depth` | 6 |
| `learning_rate` | 0.05 |
| `subsample` | 0.8 |
| `colsample_bytree` | 0.8 |
| `reg_alpha` | 0.1 |
| `reg_lambda` | 1.0 |
| Objetivo | `multi:softprob` (3 classes) |
| `early_stopping_rounds` | 30 (avaliado no TEST set) |

### Outputs

| Arquivo | Conte√∫do |
|:---|:---|
| `data/models/xgb_auditor.json` | Modelo XGBoost serializado |
| `data/models/scaler_auditor.pkl` | Scaler dos meta-features |

---

## 6Ô∏è‚É£ Binance Adapter ‚Äî Infer√™ncia Live

**Script:** `auditor_model/binance_adapter.py`

```bash
# Modo produ√ß√£o
python src/cloud/auditor_model/binance_adapter.py

# Modo teste (2 candles e encerra)
python src/cloud/auditor_model/binance_adapter.py --test-mode --max-candles 2
```

**Fluxo de dados em produ√ß√£o:**
```
Binance Futures WebSocket (btcusdt@depth@100ms)
  ‚Üì Protocolo de sync: lastUpdateId / U / u
Orderbook local reconstru√≠do (mesmo algo do ETL)
  ‚Üì resample 1 min ‚Üí 9 features ‚Üí StandardScaler
Buffer circular (720 candles)
  ‚Üì Tensor (1, 720, 9)
TCN+LSTM ‚Üí probs (1, 3)
  ‚Üì + 14 meta-features (sem warm-up)
XGBoost ‚Üí sinal calibrado (SELL / NEUTRAL / BUY)
```

**Protocolo de sincroniza√ß√£o (Constraint cr√≠tico):**
1. Abre WebSocket, bufferiza mensagens (n√£o aplica ainda)
2. Faz REST snapshot ‚Üí obt√©m `lastUpdateId`
3. Drena buffer:
   - Descarta se `u ‚â§ lastUpdateId` (j√° no snapshot)
   - Re-bootstrap se `U > lastUpdateId + 1` (gap)
   - Aplica se `U ‚â§ lastUpdateId + 1 ‚â§ u` (continuidade v√°lida)
4. Aplica deltas live normalmente

**Detec√ß√£o de drift:** cada feature √© checada contra o Z-score do scaler de treino. Se `|z| > 4.0` ‚Üí `WARNING` logado.

---

## üìÇ Logs

Todos os logs v√£o para `logs/` na raiz do projeto. Consulte [`logs/LOGS_README.md`](../../logs/LOGS_README.md) para detalhes completos.

| Pasta | Script | O que registra |
|:---|:---|:---|
| `logs/etl/` | `run_pipeline.py` | Arquivos processados, NaNs, gaps |
| `logs/labelling/` | `run_labelling.py` | Distribui√ß√£o SELL/NEU/BUY por arquivo |
| `logs/optimization/` | `run_optuna.py` | F1 por trial, OOM pruned, best params |
| `logs/training/` | `run_training.py` | Loss/F1 por epoch, checkpoint salvo |

---

## ‚ö° Hardware Recomendado

| Etapa | CPU | RAM | GPU |
|:---|:---:|:---:|:---:|
| ETL | 8+ vCPUs | 16 GB | ‚ùå |
| Labelling | 4+ vCPUs | 8 GB | ‚ùå |
| Optuna | 4 vCPUs | 16 GB | ‚úÖ RTX 3090+ |
| Training | 4 vCPUs | 16 GB | ‚úÖ RTX 3090+ |
| XGBoost | 8+ vCPUs | 32 GB | ‚ùå |
| Live | 2 vCPUs | 4 GB | Opcional |

---

## üÜò Troubleshooting

| Erro | Causa | Solu√ß√£o |
|:---|:---|:---|
| `path not found` ou `Z:\` vazio | rclone n√£o montado | Rodar mount antes do pipeline |
| `CUDA out of memory` | batch_size / seq_len alto | Reduzir `batch_size` ‚Üí 128; `seq_len` ‚Üí 720 (j√° protegido no Optuna) |
| `U > lastUpdateId + 1` no adapter | Gap no WebSocket | Re-bootstrap autom√°tico (j√° implementado) |
| Labels com 0% SELL ou BUY | Threshold muito agressivo | Ajustar `labelling_config.yaml` e re-rotular |
| ob500 vs ob200 mismatch | Arquivo 2023 com 500 n√≠veis | `transform.py` aplica hard cut autom√°tico para 200 n√≠veis |

---

## üîÅ Guia Completo RunPod (Inst√¢ncia Zerada)

```bash
# 1. Clonar e configurar
cd /workspace
git clone https://github.com/atilioebg/QuantGod_Cloud_TCNLSTM.git .
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
export PYTHONPATH=$PYTHONPATH:/workspace

# 2. Configurar rclone
mkdir -p /root/.config/rclone/
cp /workspace/rclone.conf /root/.config/rclone/rclone.conf
rclone lsd drive:   # validar conex√£o

# 3. Baixar dataset rotulado (inst√¢ncia GPU ‚Äî baixar direto no NVMe)
tmux new -s download
mkdir -p /workspace/data/L2/labelled_SELL_0004_BUY_0008_1h
rclone copy drive:PROJETOS/L2/labelled_SELL_0004_BUY_0008_1h \
  /workspace/data/L2/labelled_SELL_0004_BUY_0008_1h -P
# Ctrl+B, D (detach)

# 4. Ap√≥s download: Optuna
tmux new -s optuna
source venv/bin/activate && export PYTHONPATH=$PYTHONPATH:/workspace
python -m src.cloud.base_model.otimizacao.run_optuna

# 5. Treino final
python -m src.cloud.base_model.treino.run_training

# 6. XGBoost auditor
python -m src.cloud.auditor_model.train_xgboost

# 7. Backup dos modelos antes de desligar o Pod
rclone copy /workspace/data/models drive:PROJETOS/models -P
rclone copy /workspace/logs drive:PROJETOS/logs_backup -P
```
