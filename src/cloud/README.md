# QuantGod Cloud Infrastructure ‚òÅÔ∏è

Este diret√≥rio cont√©m o pipeline modular de Processamento e Treinamento do QuantGod, projetado para escalar horizontalmente em inst√¢ncias de nuvem (RunPod, GCP, AWS) ou rodar localmente para desenvolvimento.

---

## üõ†Ô∏è Configura√ß√£o do Ambiente

Antes de iniciar, certifique-se de satisfazer as depend√™ncias.

### 1. Instala√ß√£o de Bibliotecas
Na raiz do projeto:
```powershell
pip install -r requirements.txt
```

### 2. Conex√£o com Dados (Rclone) üîå
O pipeline **n√£o baixa** os terabytes de dados para o disco local. Ele usa **streaming** via mount de disco. Voc√™ precisa "montar" o Google Drive do projeto.

#### **Op√ß√£o A: Windows (Local / Dev)**
Use o execut√°vel `rclone.exe` j√° inclu√≠do na raiz do projeto.
1. Abra um terminal **PowerShell como Administrador**.
2. Execute o comando para montar o drive na letra `Z:`:
   ```powershell
   .\rclone.exe mount drive: Z: --vfs-cache-mode full --config rclone.conf
   ```
   *‚ö†Ô∏è Mantenha esta janela do terminal aberta enquanto estiver trabalhando.*

#### **Op√ß√£o B: Linux (Cloud / RunPod)**
Em inst√¢ncias Linux, montamos em `/workspace/gdrive`.
```bash
# Insta-le o rclone se necess√°rio
curl https://rclone.org/install.sh | sudo bash

# Configure (se ainda n√£o tiver o rclone.conf)
rclone config

# Crie a pasta e monte em background
mkdir -p /workspace/gdrive
rclone mount drive: /workspace/gdrive --vfs-cache-mode full --allow-other &
```

---

## üöÄ Pipeline de Execu√ß√£o Passo a Passo

Siga esta ordem rigorosa para reproduzir o ciclo de vida do modelo.

### 1. Pr√©-processamento (ETL) üßπ
Transforma os arquivos brutos ZIP (Bybit L2) em arquivos Parquet otimizados e limpos. 
- **Multi-Ano**: O pipeline realiza busca **recursiva** em subpastas (2023, 2024, etc.).
- **Compatibilidade**: Suporta arquivos `ob500` e `ob200` aplicando um *Hard Cut* autom√°tico para 200 n√≠veis.
- **Configura√ß√£o**: `src/cloud/pre_processamento/configs/cloud_config.yaml`
- **Output**: `data/L2/pre_processed/*.parquet`
- **Comando**:
  ```powershell
  python -m src.cloud.pre_processamento.orchestration.run_pipeline
  ```
- **Valida√ß√£o e Qualidade**:
  ```powershell
  pytest tests/test_cloud_etl_output.py
  pytest tests/test_preprocessed_quality.py
  ```

### 2. Rotulagem (Labelling) üè∑Ô∏è
Aplica a l√≥gica econ√¥mica (Thresholds Assim√©tricos) para criar os alvos (`target`): 0 (Sell), 1 (Neutral), 2 (Buy).
- **Configura√ß√£o**: `src/cloud/labelling/labelling_config.yaml`
- **Output**: `data/L2/labelled/*.parquet`
- **Comando**:
  ```powershell
  python src/cloud/labelling/run_labelling.py
  ```
- **Valida√ß√£o**: Verifica se as classes n√£o est√£o zeradas:
  ```powershell
  pytest tests/test_labelling_output.py
  ```

### 3. Otimiza√ß√£o de Hiperpar√¢metros (Optuna) üéØ
Utiliza busca Bayesiana para encontrar a melhor arquitetura do Transformer (n_heads, layers, dropout, lr), maximizando o **F1-Score Ponderado**.
- **Configura√ß√£o**: `src/cloud/otimizacao/optimization_config.yaml`
- **Comando**:
  ```powershell
  python src/cloud/otimizacao/run_optuna.py
  ```
- **Output**: 
  - `src/cloud/otimizacao/best_params.json` (Melhores configs).
  - `optuna_study.db` (Hist√≥rico da otimiza√ß√£o).

#### üìä Dashboard em Tempo Real
Para visualizar gr√°ficos de converg√™ncia e import√¢ncia de par√¢metros:
```powershell
optuna-dashboard sqlite:///optuna_study.db
# Acesse no navegador: http://127.0.0.1:8080/
```

### 4. Treinamento Final (Fine-Tuning) üß†
Treina o modelo `QuantGodModel` definitivo usando os melhores par√¢metros encontrados pelo Optuna.
- **Configura√ß√£o**: `src/cloud/treino/training_config.yaml`
- **Input**: L√™ automaticamente `best_params.json` se dispon√≠vel (ou usa o config padr√£o).
- **Comando**:
  ```powershell
  python src/cloud/treino/run_training.py
  ```
- **Output**: `data/models/quantgod_cloud_model.pth`

---

## üìÇ Logs e Auditoria
O sistema mantem logs detalhados para debugging e auditoria de performance.

| Pasta | Conte√∫do | Import√¢ncia |
| :--- | :--- | :--- |
| `logs/etl/` | Arquivos processados, erros de leitura, uso de CPU. | Alta (Integridade) |
| `logs/labelling/` | Contagem de classes (Buy/Sell), arquivos vazios. | Alta (Balanceamento) |
| `logs/optimization/` | Loss, F1 e Acur√°cia de cada trial do Optuna. | M√©dia (Performance) |
| `logs/training/` | Evolu√ß√£o da Loss e F1 por √©poca do treino final. | Alta (Converg√™ncia) |

---

## ‚ö° Performance e Hardware Recomendado

O processamento L2 √© intensivo em CPU devido √† reconstru√ß√£o do Orderbook segundo a segundo (1000ms).

*   **Processamento de ob500 (2023)**: Exige significativamente mais CPU que o ob200.
*   **Inst√¢ncia Recomendada (RunPod/Cloud)**: 
    *   M√≠nimo: **4 vCPUs** / **16GB RAM**.
    *   Ideal: **8+ vCPUs** para paralelismo m√°ximo no ETL.
*   **GPU**: Necess√°ria apenas para as etapas 3 (Optimization) e 4 (Training). Uma RTX 3090/4090 ou inst√¢ncias de A100 s√£o recomendadas para velocidade.

---

## üÜò Troubleshooting & Checklist Final

### 1. A Pegadinha do Caminho (Z:/ vs /workspace/) üìÇ
O arquivo `cloud_config.yaml` precisa ser ajustado conforme o ambiente:
- **Local (Windows)**: `rclone_mount: "Z:/PROJETOS/..."`
- **Cloud (Linux/RunPod)**: `rclone_mount: "/workspace/gdrive/..."`

### 2. Consist√™ncia ob500 vs ob200
O pipeline aplica um **Hard Cut** autom√°tico para 200 n√≠veis. Isso garante que, independentemente da profundidade do arquivo original (2023 vs 2026), o output ter√° **exatamente as mesmas colunas**, evitando erros no treinamento.

### 3. Erro: `path not found` ou `Z:\...` inexistente
- Verifique se o Rclone est√° rodando (Passo 2).
- Se estiver no Linux, verifique se o caminho no `cloud_config.yaml` aponta para `/workspace/gdrive/...`.

### 4. Erro: `Out of Memory (OOM)`
- Reduza o `batch_size` nos arquivos de configura√ß√£o `.yaml`.
- No ETL, reduza o n√∫mero de workers em `run_pipeline.py`.
