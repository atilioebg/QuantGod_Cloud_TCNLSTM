
paths:
  labelled_dir: "data/L2/labelled/labelled_SELL_0004_BUY_0008_1h"
  xgb_model_output: "data/models/xgb_auditor.json"
  scaler_output: "data/models/scaler_auditor.pkl"
  base_model_checkpoint: "data/models/best_tcn_lstm.pt"

walk_forward:
  n_folds: 5         # TCN+LSTM trains on folds 1..N-1, OOF from fold N

# Base model hyperparameters used during walk-forward fold training
# Should match final Optuna best params after optimization
base_model_hyperparameters:
  tcn_channels: 64
  lstm_hidden: 256
  num_lstm_layers: 2
  dropout: 0.3
  lr: 0.0003
  batch_size: 256
  epochs: 5          # Lower epochs per fold (speed vs fidelity tradeoff)
  inference_batch_size: 512

xgboost:
  n_estimators: 500
  max_depth: 6
  learning_rate: 0.05
  subsample: 0.8
  colsample_bytree: 0.8
  reg_alpha: 0.1
  reg_lambda: 1.0
