
paths:
  train_dir: "data/L2/splits_labelled_SELL_0004_BUY_0004_2h/train"
  val_dir: "data/L2/splits_labelled_SELL_0004_BUY_0004_2h/val"
  study_name: "quantgod_tcn_lstm_v1"
  db_path: "sqlite:///optuna_tcn_lstm_v1.db"

optimization:
  n_trials: 1
  timeout: 36000  # 10 hours
  metric: "f1_macro"  # Macro preferred over weighted to avoid Neutral domination

# TCN+LSTM search space (replaces Transformer d_model/nhead/num_layers)
search_space:
  tcn_channels: [64, 128, 256]         # Dá espaço pro TCN ficar parrudo.
  lstm_hidden: [256, 512, 1024]        # Mais memória. A A40 aguenta brincando!
  num_lstm_layers: [1, 2, 3]
  lr: [0.00001, 0.001]
  dropout: [0.1, 0.4]
  batch_size: [256, 512, 1024, 2048]        # GPU gigante pede Batches gigantes!
  epochs: 10
  seq_len: [720, 1440, 2160]           # 12h, 24h e 36h de lookback pra testar
