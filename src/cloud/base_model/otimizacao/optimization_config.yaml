
paths:
  train_dir: "data/L2/splits_labelled_SELL_0004_BUY_0004_1h/train"
  val_dir: "data/L2/splits_labelled_SELL_0004_BUY_0004_1h/val"
  study_name: "quantgod_tcn_lstm_v8"
  db_path: "sqlite:///optuna_tcn_lstm_v8.db"

optimization:
  n_trials: 50
  timeout: 72000  # 20 hours (Estimativa: 50 trials * 20 min = 16.6h + margem)
  metric: "f1_macro"  # Macro volta a ser o objetivo do Optuna

# TCN+LSTM search space
search_space:
  # 1. Redução Extrema de Capacidade (Matando a Memorização)
  tcn_channels: [16, 32, 64]         # Inserido 16, removido 128. O Alpha L2 não exige tantas convoluções.
  lstm_hidden: [32, 64, 128]         # REMOVIDO o 256. Proibido dar cérebro excedente para a rede decorar o Neutro.
  num_lstm_layers: [1, 2]            # Mantido.

  # 2. O Freio do Otimizador (O Ajuste Mais Importante)
  lr: [0.00001, 0.0005]              # Teto cortado de 0.002 para 0.0005. Impede saltos bruscos que rompam a Focal Loss.

  # 3. Manutenção dos Escudos
  dropout: [0.3, 0.6]                # Mantido.
  batch_size: [512, 1024, 2048]      # Corrigido 521 → 512.
  epochs: 10
  seq_len: [180, 360, 720]           # Inserido 180 (3h). A microestrutura pode ser ainda mais rápida.