# üìÅ logs/ ‚Äî Logging Directory

Esta pasta centraliza **todos os logs em tempo de execu√ß√£o** do pipeline QuantGod Cloud.
Cada subpasta corresponde a uma etapa distinta do sistema e √© populada automaticamente
ao executar os scripts correspondentes.

> **Importante:** Nenhum arquivo de log √© versionado pelo git (exceto `.gitkeep` para preservar a estrutura de diret√≥rios). Adicione `logs/**/*.log` ao `.gitignore` caso ainda n√£o esteja.

---

## üìÇ Estrutura de Subpastas

```
logs/
‚îú‚îÄ‚îÄ debug_plots/        ‚Üê Gr√°ficos de diagn√≥stico (ETL, features, distribui√ß√µes)
‚îú‚îÄ‚îÄ etl/                ‚Üê Logs do pipeline de extra√ß√£o, transforma√ß√£o e carga
‚îú‚îÄ‚îÄ labelling/          ‚Üê Logs da gera√ß√£o de labels SELL/NEUTRAL/BUY
‚îú‚îÄ‚îÄ optimization/       ‚Üê Logs de cada trial Optuna + best params encontrados
‚îú‚îÄ‚îÄ training/           ‚Üê Logs do treinamento do Hybrid_TCN_LSTM por epoch
‚îî‚îÄ‚îÄ .gitkeep            ‚Üê Mant√©m a estrutura de diret√≥rios no reposit√≥rio
```

---

## üìÅ `etl/`

**Gerado por:** `src/cloud/base_model/pre_processamento/orchestration/run_pipeline.py`

**Conte√∫do:** Um arquivo por execu√ß√£o do pipeline ETL, nomeado com timestamp:
```
etl/etl_YYYYMMDD_HHMMSS.log
```

**O que est√° registrado:**
- Arquivos ZIP encontrados no GDrive (via rclone)
- Snapshot inicial do orderbook recebido para cada arquivo
- N√∫mero de linhas geradas ap√≥s resample de 1 minuto
- Valores de NaN/Infinity detectados pelo `DataValidator`
- Gaps temporais significativos no orderbook
- Caminho do arquivo Parquet salvo e tamanho final
- Erros de processamento por arquivo (continua nos pr√≥ximos sem parar)

**Formato de exemplo:**
```
2026-02-18 10:32:01 [INFO]  Processing: 2025-03-14_BTCUSDT_ob200.data.zip
2026-02-18 10:32:03 [INFO]  Rows after resample: 1440
2026-02-18 10:32:03 [INFO]  Saved: data/L2/pre_processed/2025-03-14.parquet (2.1 MB)
```

---

## üìÅ `labelling/`

**Gerado por:** `src/cloud/base_model/labelling/run_labelling.py`

**Conte√∫do:**
```
labelling/labelling_processing.log           ‚Üê Log acumulativo de todas as execu√ß√µes
labelling/labelling_SUFIXO_YYYYMMDD_HHMMSS.log  ‚Üê Log por configura√ß√£o espec√≠fica
```

> O sufixo do arquivo √© derivado automaticamente do `labelled_dir` configurado em `labelling_config.yaml` (ex: `SELL_0004_BUY_0008_1h`). Isso garante que rodar com configura√ß√µes diferentes nunca sobrescreva logs anteriores.

**O que est√° registrado:**
- Configura√ß√£o usada: `lookahead`, `threshold_long`, `threshold_short`
- Arquivos processados em paralelo (`ProcessPoolExecutor`)
- Distribui√ß√£o de labels por arquivo (SELL / NEUTRAL / BUY em %)
- Distribui√ß√£o final agregada de todo o dataset
- Erros de processamento isolados por arquivo

**Formato de exemplo:**
```
2026-02-19 14:21:05 [INFO]  Config: lookahead=60, short=-0.004, long=0.008
2026-02-19 14:21:06 [INFO]  2025-03-14.parquet ‚Üí SELL: 12.3% | NEU: 74.1% | BUY: 13.6%
2026-02-19 14:22:30 [INFO]  FINAL DISTRIBUTION ‚Üí SELL: 11.8% | NEU: 75.2% | BUY: 13.0%
```

---

## üìÅ `optimization/`

**Gerado por:** `src/cloud/base_model/otimizacao/run_optuna.py`

**Conte√∫do:**
```
optimization/optimization_SUFIXO_YYYYMMDD_HHMMSS.log
```

> O sufixo √© derivado do `labelled_dir` ‚Äî o mesmo mecanismo do labelling ‚Äî para rastreabilidade entre configura√ß√£o de dados e resultado da otimiza√ß√£o.

**O que est√° registrado:**
- Par√¢metros testados em cada trial (`tcn_channels`, `lstm_hidden`, `lr`, `dropout`, `seq_len`, etc.)
- F1 Macro e F1 por classe (SELL/NEUTRAL/BUY) por epoch de cada trial
- LR atual a cada epoch (CosineAnnealingLR)
- Trials pruned pelo `MedianPruner` ou por OOM (CUDA out of memory)
- Melhor trial ao final e seus par√¢metros

**Formato de exemplo:**
```
2026-02-20 09:14:00 [INFO]  Trial 3 START | tcn=64, lstm=256, seq=720, lr=0.000312
2026-02-20 09:16:40 [INFO]  Trial 3, Epoch 3/5 | F1 Macro: 0.4821 | F1 [S/N/B]: [0.441/0.523/0.483]
2026-02-20 09:18:00 [WARNING] Trial 7 ‚Äî CUDA OOM! Clearing cache and pruning...
2026-02-20 09:45:00 [INFO]  Best F1 Macro: 0.5103 | Params: {tcn_channels: 64, lstm_hidden: 256, ...}
```

---

## üìÅ `training/`

**Gerado por:** `src/cloud/base_model/treino/run_training.py`

**Conte√∫do:**
```
training/training_YYYYMMDD_HHMMSS.log
```

**O que est√° registrado:**
- Device utilizado (CUDA / CPU) e n√∫mero de par√¢metros do modelo
- Class weights carregados de `base_model_config.yaml`
- Progresso por batch (a cada 200 batches): loss atual e % do epoch
- Por epoch completo:
  - Train Loss e Val Loss m√©dios
  - F1 Macro e F1 Weighted
  - F1 por classe: `[SELL / NEUTRAL / BUY]`
  - Learning Rate atual
- Checkpoint salvo quando F1 Macro melhora
- Early stopping ativado (com o epoch em que ocorreu)

**Formato de exemplo:**
```
2026-02-20 11:00:00 [INFO]  Device: cuda | Parameters: 1,842,819
2026-02-20 11:00:00 [INFO]  CrossEntropyLoss weights: [2.0, 1.0, 2.0]
2026-02-20 11:03:22 [INFO]  Epoch 1/10 | Train Loss: 0.8841 | Val Loss: 0.9102
                             F1 Macro: 0.4103 | F1 [S/N/B]: [0.381/0.452/0.398] | LR: 0.000300
2026-02-20 11:03:22 [INFO]  ‚úÖ Best model saved (F1 Macro: 0.4103)
```

---

## üìÅ `debug_plots/`

**Gerado por:** scripts de diagn√≥stico e an√°lise explorat√≥ria (uso manual).

**Conte√∫do:** Imagens `.png` geradas durante an√°lises de:
- Distribui√ß√£o de features (histogramas pr√©/p√≥s normaliza√ß√£o)
- S√©ries temporais de micro_price e features derivadas
- Matrizes de correla√ß√£o de features
- An√°lise de distribui√ß√£o de labels por per√≠odo

> Esta pasta √© de uso **exclusivamente manual/diagn√≥stico**. N√£o √© populada pelo pipeline automatizado.

---

## ‚öôÔ∏è Boas Pr√°ticas

### Reten√ß√£o de Logs
- **ETL e Labelling:** manter os √∫ltimos 30 arquivos (1 por dia processado)
- **Optimization:** manter todos ‚Äî cada arquivo documenta um experimento √∫nico
- **Training:** manter todos ‚Äî cada arquivo corresponde a um modelo salvo espec√≠fico

### Naming Convention
Todos os arquivos seguem o padr√£o:
```
{modulo}_{sufixo_config}_{YYYYMMDD_HHMMSS}.log
```
O sufixo de configura√ß√£o previne sobrescrita ao rodar experimentos com par√¢metros diferentes.

### Limpeza Manual (RunPod)
Ao encerrar um Pod, comprimir os logs antes de desligar:
```bash
tar -czf logs_backup_$(date +%Y%m%d).tar.gz logs/
rclone copy logs_backup_*.tar.gz drive:QuantGod/logs_backup/
```

### Rota√ß√£o de Logs (Opcional)
Para execu√ß√µes cont√≠nuas de longa dura√ß√£o, configurar rota√ß√£o via `logging.handlers.RotatingFileHandler`:
```python
handler = RotatingFileHandler(log_path, maxBytes=50*1024*1024, backupCount=5)
# M√°ximo 50 MB por arquivo, mant√©m 5 backups
```
